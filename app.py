# -*- coding: utf-8 -*-
"""LDA_streamlit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yS4n07UGjwX9y0GzGG7x0IDFqUllegHN
"""

import streamlit as st
import numpy as np
import pandas as pd
import ast

import gensim as gs
from gensim import corpora
from gensim.models import CoherenceModel
from gensim.models import LdaModel
from datetime import datetime

import pyLDAvis
import pyLDAvis.gensim_models as gensimvis

# Streamlit í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title="LDA í† í”½ ëª¨ë¸ë§ ì‹œê°í™”",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded",
)

# í˜ì´ì§€ ì œëª© ì„¤ì •
st.title("TMNLP ê²½ì œ ê¸°ì‚¬ ë¶„ì„")

# ì‚¬ì´ë“œë°” ì œëª©
st.sidebar.header("")

# --- í•¨ìˆ˜ ì •ì˜ ---
@st.cache_data
def load_and_filter_data(file_path, start_date, end_date):
    try:
        # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
        tokenized_articles_df = pd.read_csv(file_path, encoding='utf-8-sig')

        # 'tokens' ì»¬ëŸ¼ ë³€í™˜
        tokenized_articles_df['tokens'] = tokenized_articles_df['tokens'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)

        # ë‚ ì§œ í˜•ë³€í™˜
        tokenized_articles_df['date'] = pd.to_datetime(tokenized_articles_df['date'], format='%Y.%m.%d')

        # ì§€ì •ëœ ê¸°ê°„ ë‚´ ë°ì´í„° í•„í„°ë§
        filtered_df = tokenized_articles_df[(tokenized_articles_df['date'] >= pd.to_datetime(start_date)) & (tokenized_articles_df['date'] <= pd.to_datetime(end_date))]

        st.success(f"{start_date} ~ {end_date} ê¸°ê°„ì˜ ê¸°ì‚¬ {len(filtered_df)}ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")  # ì„±ê³µ ë©”ì‹œì§€ í‘œì‹œ

        return filtered_df

    except FileNotFoundError:
        st.error(f"ì˜¤ë¥˜: í•´ë‹¹ íŒŒì¼ '{file_path}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None
    except Exception as e:
        st.error(f"ì˜¤ë¥˜: ë°ì´í„° ë¡œë”© ë° í•„í„°ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# ë‹¨ì–´ ì‚¬ì „ ë° BoW ì½”í¼ìŠ¤ ìƒì„± í•¨ìˆ˜
@st.cache_data
def create_dictionary_and_corpus(filtered_df):
    try:
        with st.spinner("ë‹¨ì–´ ì‚¬ì „ ë° BoW ì½”í¼ìŠ¤ ìƒì„± ì¤‘..."):
            # ë‹¨ì–´ ì‚¬ì „ ìƒì„±
            dictionary = corpora.Dictionary(filtered_df['tokens'])

            # BoW ì½”í¼ìŠ¤ ìƒì„±
            corpus = [dictionary.doc2bow(tokens) for tokens in filtered_df['tokens']]

        return dictionary, corpus

    except Exception as e:
        st.error(f"ì˜¤ë¥˜: ë‹¨ì–´ ì‚¬ì „ ë° BoW ì½”í¼ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None

# LDA ëª¨ë¸ í•™ìŠµ ë° ìµœì  í† í”½ ìˆ˜ ê²°ì • í•¨ìˆ˜
def train_lda_model(corpus, dictionary, filtered_df):
    topic_range = range(2, 10)  # í† í”½ ê°œìˆ˜ ë²”ìœ„ë¥¼ 2~9ë¡œ ê³ ì •
    try:
        with st.spinner("ìµœì  í† í”½ ê°œìˆ˜ íƒìƒ‰ ë° LDA ëª¨ë¸ í•™ìŠµ ì¤‘..."):
            coherence_scores = []
            num_topics_list = list(topic_range) # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì¸ë±ìŠ¤ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ í•¨

            # ì§„í–‰ë¥  í‘œì‹œë°” ì´ˆê¸°í™”
            progress_bar = st.progress(0)
            progress_text = "ì‘ì§‘ë„ ê³„ì‚° ì§„í–‰ ì¤‘..."
            status_text = st.empty() # ìƒíƒœ ë©”ì‹œì§€ë¥¼ í‘œì‹œí•  ë¹ˆ ê³µê°„ í™•ë³´

            for i, num_topics in enumerate(num_topics_list):
                # LDA ëª¨ë¸ í•™ìŠµ
                lda_model = gs.models.ldamodel.LdaModel(
                    corpus=corpus,
                    id2word=dictionary,
                    num_topics=num_topics,
                    passes=15,
                    random_state=42
                )

                # ì‘ì§‘ë„ ê³„ì‚°
                coherence_model = CoherenceModel(
                    model=lda_model,
                    texts=filtered_df['tokens'],
                    dictionary=dictionary,
                    coherence='c_v'
                )
                coherence_lda = coherence_model.get_coherence()
                coherence_scores.append(coherence_lda)

                # ì§„í–‰ë¥  í‘œì‹œë°” ì—…ë°ì´íŠ¸
                progress_value = (i + 1) / len(num_topics_list)
                progress_bar.progress(progress_value, text=f"{progress_text} ({progress_value*100:.1f}%)")

            # ìµœì  í† í”½ ê°œìˆ˜ ê²°ì •
            if coherence_scores:
                max_coherence = max(coherence_scores)
                optimal_topic_index = coherence_scores.index(max_coherence)
                best_topic_num = num_topics_list[optimal_topic_index]

                st.success(f"ìµœì  í† í”½ ìˆ˜: {best_topic_num} (ì‘ì§‘ë„: {max_coherence:.4f})") # ì‘ì§‘ë„ ê°’ë„ í•¨ê»˜ í‘œì‹œ

            else:
                st.warning("ì‘ì§‘ë„ ì ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None, None

            # ìµœì¢… LDA ëª¨ë¸ í•™ìŠµ (ìµœì  í† í”½ ê°œìˆ˜ë¡œ)
            final_lda_model = gs.models.ldamodel.LdaModel(
                corpus=corpus,
                id2word=dictionary,
                num_topics=best_topic_num, # ìµœì  í† í”½ ê°œìˆ˜ ì‚¬ìš©
                passes=15, # passes ê°’ ì¡°ì • ê°€ëŠ¥
                random_state=42
            )
            return best_topic_num, final_lda_model # í•™ìŠµëœ ìµœì¢… ëª¨ë¸ ë°˜í™˜

    except Exception as e:
        st.error(f"ì˜¤ë¥˜: LDA ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.error(e) # ìƒì„¸ ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œ
        return None, None



# --- UI ìš”ì†Œ ---
st.header("ë¶„ì„ ê¸°ê°„ ì„¤ì •") # ì‚¬ì´ë“œë°” -> ë©”ì¸ í™”ë©´
col1, col2 = st.columns(2) # ë‘ ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ ë‚˜ëˆ„ê¸°

with col1:
    start_date = st.date_input("ì‹œì‘ ë‚ ì§œ", value=datetime(2025, 2, 1))
with col2:
    end_date = st.date_input("ì¢…ë£Œ ë‚ ì§œ", value=datetime(2025, 4, 30))

# íŒŒì¼ ê²½ë¡œ ì„¤ì •
file_path = './tokenized_articles.csv'

# ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
if st.button("ë¶„ì„ ì‹¤í–‰"):
    st.write("ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    # ë°ì´í„° ë¡œë”© ë° í•„í„°ë§
    filtered_df = load_and_filter_data(file_path, start_date, end_date)

    if filtered_df is not None:
        # ë‹¨ì–´ ì‚¬ì „ ë° BoW ì½”í¼ìŠ¤ ìƒì„±
        dictionary, corpus = create_dictionary_and_corpus(filtered_df)

        if dictionary is not None and corpus is not None:
            # LDA ëª¨ë¸ í•™ìŠµ ë° ìµœì  í† í”½ ìˆ˜ ê²°ì •
            lda_model = train_lda_model(corpus, dictionary, filtered_df)

            if lda_model is not None:
                st.write("LDA ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")

                # pyLDAvis ì‹œê°í™”
                try:
                    with st.spinner("pyLDAvis ì‹œê°í™” ì¤€ë¹„ ì¤‘..."):
                        vis = gensimvis.prepare(lda_model[1], corpus, dictionary) # lda_model íŠœí”Œì˜ ë‘ ë²ˆì§¸ ìš”ì†Œê°€ ëª¨ë¸
                        st.success("pyLDAvis ì‹œê°í™”")
                    pyldavis_html = pyLDAvis.prepared_data_to_html(vis)
		            st.components.v1.html(pyldavis_html, width=None, height=800, scrolling=True) 

                except Exception as e:
                    st.error(f"ì˜¤ë¥˜: pyLDAvis ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    st.error("pyLDAvis ì‹œê°í™”ê°€ ì œëŒ€ë¡œ í‘œì‹œë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (Colab í™˜ê²½)")

