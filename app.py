# -*- coding: utf-8 -*-
"""LDA_streamlit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yS4n07UGjwX9y0GzGG7x0IDFqUllegHN
"""

import streamlit as st
import numpy as np
import pandas as pd
import ast

import gensim as gs
from gensim import corpora
from gensim.models import CoherenceModel
from gensim.models import LdaModel
from datetime import datetime

import pyLDAvis
import pyLDAvis.gensim_models as gensimvis

import matplotlib.pyplot as plt
from wordcloud import WordCloud

import openai
import os
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë”©
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

from openai import OpenAI
client = OpenAI()


# Streamlit í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(
    page_title="LDA í† í”½ ëª¨ë¸ë§ ì‹œê°í™”",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded",
)

# í˜ì´ì§€ ì œëª© ì„¤ì •
st.title("TMNLP ê²½ì œ ê¸°ì‚¬ ë¶„ì„")

# ì‚¬ì´ë“œë°” ì œëª©
st.sidebar.header("")

# --- í•¨ìˆ˜ ì •ì˜ ---
@st.cache_data
def load_and_filter_data(file_path, start_date, end_date):
    try:
        # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
        tokenized_articles_df = pd.read_csv(file_path, encoding='utf-8-sig')

        # 'tokens' ì»¬ëŸ¼ ë³€í™˜
        tokenized_articles_df['tokens'] = tokenized_articles_df['tokens'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)

        # ë‚ ì§œ í˜•ë³€í™˜
        tokenized_articles_df['date'] = pd.to_datetime(tokenized_articles_df['date'], format='%Y.%m.%d')

        # ì§€ì •ëœ ê¸°ê°„ ë‚´ ë°ì´í„° í•„í„°ë§
        filtered_df = tokenized_articles_df[(tokenized_articles_df['date'] >= pd.to_datetime(start_date)) & (tokenized_articles_df['date'] <= pd.to_datetime(end_date))]

        st.success(f"{start_date} ~ {end_date} ê¸°ê°„ì˜ ê¸°ì‚¬ {len(filtered_df)}ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")  # ì„±ê³µ ë©”ì‹œì§€ í‘œì‹œ

        return filtered_df

    except FileNotFoundError:
        st.error(f"ì˜¤ë¥˜: í•´ë‹¹ íŒŒì¼ '{file_path}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None
    except Exception as e:
        st.error(f"ì˜¤ë¥˜: ë°ì´í„° ë¡œë”© ë° í•„í„°ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# ë‹¨ì–´ ì‚¬ì „ ë° BoW ì½”í¼ìŠ¤ ìƒì„± í•¨ìˆ˜
@st.cache_data
def create_dictionary_and_corpus(filtered_df):
    try:
        with st.spinner("ë‹¨ì–´ ì‚¬ì „ ë° BoW ì½”í¼ìŠ¤ ìƒì„± ì¤‘..."):
            # ë‹¨ì–´ ì‚¬ì „ ìƒì„±
            dictionary = corpora.Dictionary(filtered_df['tokens'])

            # BoW ì½”í¼ìŠ¤ ìƒì„±
            corpus = [dictionary.doc2bow(tokens) for tokens in filtered_df['tokens']]

        return dictionary, corpus

    except Exception as e:
        st.error(f"ì˜¤ë¥˜: ë‹¨ì–´ ì‚¬ì „ ë° BoW ì½”í¼ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None

# LDA ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜
def build_lda_model(corpus, dictionary, num_topics, passes=15, random_state=42):
    return gs.models.ldamodel.LdaModel(
        corpus=corpus,
        id2word=dictionary,
        num_topics=num_topics,
        passes=passes,
        random_state=random_state
    )

# LDA ëª¨ë¸ í•™ìŠµ ë° ìµœì  í† í”½ ìˆ˜ ê²°ì • í•¨ìˆ˜
def train_lda_model(corpus, dictionary, filtered_df):
    topic_range = range(2, 10)
    try:
        with st.spinner("ìµœì  í† í”½ ê°œìˆ˜ íƒìƒ‰ ë° LDA ëª¨ë¸ í•™ìŠµ ì¤‘..."):
            coherence_scores = []
            num_topics_list = list(topic_range)

            progress_bar = st.progress(0)
            progress_text = "ì‘ì§‘ë„ ê³„ì‚° ì§„í–‰ ì¤‘..."
            status_text = st.empty()

            for i, num_topics in enumerate(num_topics_list):
                lda_model = build_lda_model(corpus, dictionary, num_topics)

                coherence_model = CoherenceModel(
                    model=lda_model,
                    texts=filtered_df['tokens'],
                    dictionary=dictionary,
                    coherence='c_v'
                )
                coherence_lda = coherence_model.get_coherence()
                coherence_scores.append(coherence_lda)

                progress_value = (i + 1) / len(num_topics_list)
                progress_bar.progress(progress_value, text=f"{progress_text} ({progress_value*100:.1f}%)")

            if coherence_scores:
                max_coherence = max(coherence_scores)
                optimal_topic_index = coherence_scores.index(max_coherence)
                best_topic_num = num_topics_list[optimal_topic_index]

                st.success(f"ìµœì  í† í”½ ìˆ˜: {best_topic_num} (ì‘ì§‘ë„: {max_coherence:.4f})")
            else:
                st.warning("ì‘ì§‘ë„ ì ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None, None

            final_lda_model = build_lda_model(corpus, dictionary, best_topic_num)
            return best_topic_num, final_lda_model

    except Exception as e:
        st.error(f"ì˜¤ë¥˜: LDA ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None


def generate_wordcloud(filtered_df, start_date, end_date):
    if not filtered_df.empty and 'tokens' in filtered_df.columns:
        with st.spinner("ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘..."):
            try:
                all_tokens = [token for tokens_list in filtered_df['tokens'].dropna().tolist() for token in tokens_list]
                text_for_wordcloud = ' '.join(all_tokens)
                font_path = './NanumBarunGothic.ttf'
                wordcloud = WordCloud(
                    font_path=font_path,
                    width=800, height=400, 
                    background_color='white', 
                    max_words=100, 
                    colormap='viridis'
                )
                wordcloud.generate(text_for_wordcloud)
                fig, ax = plt.subplots(figsize=(10, 5))
                ax.imshow(wordcloud, interpolation='bilinear')
                ax.axis('off')
                ax.set_title(f"'{start_date.strftime('%Y.%m.%d')}' ~ '{end_date.strftime('%Y.%m.%d')}'", fontsize=14)
                plt.close(fig)
                return fig
            
            except Exception as e:
                st.error(f"ì˜¤ë¥˜: ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                st.error(e)
                return None
    else:
        st.warning("\nì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤ (í•„í„°ë§ëœ ë°ì´í„° ì—†ìŒ).")
        return None

# GPT ìš”ì•½ í•¨ìˆ˜
def summarize_topics_with_gpt(_lda_model, topn=10, model_name="gpt-4o"):
    try:
        summaries = []

        for topic_id in range(_lda_model.num_topics):
            top_words = _lda_model.show_topic(topic_id, topn=topn)
            keyword_list = [word for word, _ in top_words]
            prompt = (
                f"ë‹¤ìŒì€ ê²½ì œ ê¸°ì‚¬ ë¶„ì„ ê²°ê³¼ì—ì„œ ì¶”ì¶œëœ í† í”½ í‚¤ì›Œë“œì…ë‹ˆë‹¤:\n"
                f"{', '.join(keyword_list)}\n\n"
                "ì´ í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•´ë‹¹ í† í”½ì„ ê°„ê²°í•˜ê³  ì§ê´€ì ì¸ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”."
            )

            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ê²½ì œ ê¸°ì‚¬ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=100,
                temperature=0.7
            )
            summary = response.choices[0].message.content.strip()
            summaries.append((topic_id, summary))

        return summaries

    except Exception as e:
        st.error(f"GPT ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

# --- UI ìš”ì†Œ ---
st.header("ë¶„ì„ ê¸°ê°„ ì„¤ì • (2025ë…„ 2ì›”~4ì›” ë¶„ì„ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.)") # ì‚¬ì´ë“œë°” -> ë©”ì¸ í™”ë©´
col1, col2 = st.columns(2) # ë‘ ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ ë‚˜ëˆ„ê¸°

with col1:
    start_date = st.date_input("ì‹œì‘ ë‚ ì§œ", value=datetime(2025, 2, 1))
with col2:
    end_date = st.date_input("ì¢…ë£Œ ë‚ ì§œ", value=datetime(2025, 4, 30))

# íŒŒì¼ ê²½ë¡œ ì„¤ì •
file_path = './tokenized_articles.csv'

if 'lda_vis_html' not in st.session_state:
    st.session_state.lda_vis_html = None
if 'wordcloud_fig' not in st.session_state:
    st.session_state.wordcloud_fig = None
if 'topic_summaries' not in st.session_state:
    st.session_state.topic_summaries = None
    
# ì‹œê°í™” ì„ íƒ ë¼ë””ì˜¤ ë²„íŠ¼
visualization_option = st.radio(
    "RESULT: ",
    ('LDA', 'wordCloud', 'summary')
)
    
if st.button("ë¶„ì„ ì‹¤í–‰"):
    filtered_df = load_and_filter_data(file_path, start_date, end_date)

    if filtered_df is not None:
        dictionary, corpus = create_dictionary_and_corpus(filtered_df)

        st.session_state.lda_vis_html = None
        if dictionary is not None and corpus is not None:
            lda_model = train_lda_model(corpus, dictionary, filtered_df)
            if lda_model is not None:
                try:
                    with st.spinner("pyLDAvis ì‹œê°í™” ì¤€ë¹„ ì¤‘..."):
                        vis = gensimvis.prepare(lda_model[1], corpus, dictionary)
                        st.session_state.lda_vis_html = pyLDAvis.prepared_data_to_html(vis)
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜: pyLDAvis ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    st.session_state.lda_vis_html = None
                    
            # GPT ìš”ì•½ ì‹¤í–‰
            st.info("GPT ìš”ì•½ ìƒì„± ì¤‘...")
            topic_summaries = summarize_topics_with_gpt(lda_model[1])
            st.session_state.topic_summaries = topic_summaries
            st.success("GPT ìš”ì•½ ì™„ë£Œ")

         # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
        st.session_state.wordcloud_fig = None
        if not filtered_df.empty and 'tokens' in filtered_df.columns:
            st.info("ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘...")
            st.session_state.wordcloud_fig = generate_wordcloud(filtered_df, start_date, end_date)
            if st.session_state.wordcloud_fig:
                st.success("ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì™„ë£Œ!")

# ê²°ê³¼ë§Œ ë²ˆê°ˆì•„ ë³´ì—¬ì£¼ê¸°
if visualization_option == 'LDA':
    if st.session_state.lda_vis_html:
        st.components.v1.html(st.session_state.lda_vis_html, width=None, height=800, scrolling=True)
    else:
        st.info("LDA ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¶„ì„ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
elif visualization_option == 'wordCloud':
    if st.session_state.wordcloud_fig:
        st.pyplot(st.session_state.wordcloud_fig)
    else:
        st.info("ì›Œë“œí´ë¼ìš°ë“œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¶„ì„ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
elif visualization_option == 'summary':
    if st.session_state.topic_summaries:
        st.subheader("GPT ê¸°ë°˜ í† í”½ ìš”ì•½")
        for topic_id, summary in st.session_state.topic_summaries:
            st.markdown(f"**í† í”½ {topic_id + 1}**: {summary}")
    else:
        st.info("ìš”ì•½ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¶„ì„ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        
